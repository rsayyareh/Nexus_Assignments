{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6pr9RxJiBKU"
   },
   "source": [
    "# ğŸ  Mini-Project: Preprocess & Engineer Features on Ames Housing Dataset\n",
    "\n",
    "> **Goal: Work with the [Ames Housing dataset](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset?select=AmesHousing.csv) to perform data preprocessing and create meaningful new features. You will:**\n",
    "> - Handle **missing values**, **duplicates**, and **outliers**  \n",
    "> - Detect and fix **skewness** in numerical features  \n",
    "> - Encode categorical variables into numeric formats  \n",
    "> - Create **non-linear features** (e.g., polynomial, log, interaction terms) from existing variables  \n",
    "> - Save the cleaned and enriched dataset into a new CSV file  \n",
    "\n",
    "<p align=\"center\">ğŸ“¢âš ï¸ğŸ“‚</p>\n",
    "\n",
    "<p align=\"center\"> Please name your file using the format: <code>assignmentName_nickname.py/.ipynb</code> (e.g., <code>project2_rezashokrzad.py</code>) and push it to GitHub with a clear commit message.</p>\n",
    "\n",
    "<p align=\"center\"> ğŸš¨ğŸ“ğŸ§ </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CksOccRjV4s"
   },
   "source": [
    "## ğŸ”¹ Step 1: Load the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "Nlz-ZiyHgmQb",
    "outputId": "b7590ba0-2688-4858-e23d-499faedb3244"
   },
   "source": [
    "# TODO: Load the Ames Housing dataset into a DataFrame.\n",
    "# Hint: The dataset is available on Kaggle (\"Ames Housing\").\n",
    "# After loading, display the first and last 5 rows to check if it worked.\n",
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"AmesHousing.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"shashanknecrothapa/ames-housing-dataset\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like\n",
    "  # sql_query or pandas_kwargs. See the\n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "\n",
    "df.head(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdX7swaujg_u"
   },
   "source": [
    "## ğŸ”¹ Step 2: Exploratory Data Review (EDR)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMYRBPWWjgpo",
    "outputId": "bb5e68b6-60c3-4338-d268-1fcec406b094"
   },
   "source": [
    "# TODO: Perform initial exploration of the dataset.\n",
    "# - Check shape, column names, smaples\n",
    "# - Get summary info, data types\n",
    "# - Descriptive statistics\n",
    "\n",
    "df.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBv7xfjbmjie",
    "outputId": "c943f2cd-3922-42da-e7ba-ee295a137615"
   },
   "source": [
    "df.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkrV9mGCmlTf",
    "outputId": "b3658c9f-1150-4b0f-8ed0-22cfae551a0f"
   },
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "PQ0YzHK5mnbL",
    "outputId": "6dfbac75-b499-4f21-a3ae-5000fcace5dd"
   },
   "source": [
    "df.sample(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "M8lUA1Chmn5Y",
    "outputId": "69e8ce0c-6885-40fe-fe78-163b19f5427c"
   },
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h4A675lMmp3q",
    "outputId": "06d868dc-15ee-4ab3-d004-89ae4a202569"
   },
   "source": [
    "df.nunique()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Check and remove duplicate rows if there is.\n",
    "\n",
    "df.duplicated().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UrCG4fmTbcE",
    "outputId": "21b1a51f-76db-40c6-b6c0-468c13d134a5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quTZ6mJdjrDw"
   },
   "source": [
    "## ğŸ”¹ Step 3: Missing Value Check & Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "-0KdWkPqjs7y",
    "outputId": "5c52b5c1-6106-43e0-e537-1eaae5033831"
   },
   "source": [
    "# TODO: Check missing values.\n",
    "# Decide on a strategy (if needed):\n",
    "# - Drop if too many are missing\n",
    "# - Fill with mean/median/mode/domain-specific value\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "df.isnull().sum()\n",
    "df.isnull().sum()[df.isnull().sum() > 0].sort_values(ascending=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8D2A5akpQzf",
    "outputId": "957a8793-95eb-412d-a82d-913dad2b3ab3"
   },
   "source": [
    "#drop na\n",
    "df.dropna(thresh = 70, inplace=True)\n",
    "df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bXPlafzHm2yP",
    "outputId": "8e53b0dc-6330-4dc1-8554-92cbc4826f6c"
   },
   "source": [
    "for col in df.select_dtypes(include=[\"float64\", \"int64\"]).columns:   #for numerics fill with median\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "\n",
    "for col in df.select_dtypes(include=[\"object\"]).columns: # for objects fill with mode\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeL71KO0r-ix",
    "outputId": "64859f35-4c96-4913-c23d-eae25030da0b"
   },
   "source": [
    "df.isnull().sum().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv4QElCCr3oa",
    "outputId": "4512dc08-7d80-46c1-e33d-84e760f7d5fb"
   },
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuuDgx_Js4B3",
    "outputId": "c7edf127-14ea-4738-950b-e03d09f84fdb"
   },
   "source": [
    "\n",
    "# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ Ø³ØªÙˆÙ†\n",
    "def is_numeric_but_object(series):\n",
    "    if series.dtype == 'object':\n",
    "        converted = pd.to_numeric(series, errors='coerce')\n",
    "        non_na_ratio = converted.notna().sum() / len(series)\n",
    "        return non_na_ratio == 1  # 100% numeric\n",
    "    else:\n",
    "        return False  # Ø®ÙˆØ¯Ø´ numeric Ù†ÛŒØ³Øª object Ú©Ù‡ Ù†Ø¨Ø§Ø´Ù‡\n",
    "\n",
    "# Ù„ÛŒØ³Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ object Ù‡Ø³ØªÙ† ÙˆÙ„ÛŒ numeric\n",
    "numeric_like_objects = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if is_numeric_but_object(df[col]):\n",
    "        numeric_like_objects.append(col)\n",
    "\n",
    "print(\"Columns that are object but fully numeric:\", numeric_like_objects)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWQY6vDEjyTu"
   },
   "source": [
    "## ğŸ”¹ Step 4: Correlation Check & Feature Decision"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MHwMZbX_jxKJ",
    "outputId": "9c900208-39a0-4d97-e214-057a61316b7f"
   },
   "source": [
    "# TODO: Check correlations between numerical features and target variable (SalePrice).\n",
    "# Use correlation heatmap or pairplot.\n",
    "# Decide which features to keep/remove based on correlation.\n",
    "\n",
    "df.corr(numeric_only=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B61laKs8ufhA",
    "outputId": "eda3c0b6-9f53-4c57-ca60-3abb45e0fa90"
   },
   "source": [
    "# ÙÙ‚Ø· correlation Ù‡Ø± Ø³ØªÙˆÙ† Ø¨Ø§ target\n",
    "cor_target = df.corr(numeric_only=True)['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6, 12))  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø³ØªÙˆÙ†\n",
    "sns.heatmap(cor_target.to_frame(), annot=True, cmap='coolwarm')  # ØªØ¨Ø¯ÛŒÙ„ Series Ø¨Ù‡ DataFrame\n",
    "plt.title(\"Correlation of Features with SalePrice\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "XzbUjqlg0JGO",
    "outputId": "59c806d3-7dd9-4f0b-8253-7e9d424b92b9"
   },
   "source": [
    "df.shape\n",
    "df.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exTa7T6qj2hv"
   },
   "source": [
    "## ğŸ”¹ Step 5: Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GJ6eriJ1yDNU"
   },
   "source": [
    "num_cols = df.select_dtypes(exclude=['object']).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JBQbfP6jj1hS"
   },
   "source": [
    "# TODO: Identify categorical variables.\n",
    "# Use methods like:\n",
    "# - One-hot encoding\n",
    "# - Ordinal encoding\n",
    "# Decide what makes sense for each feature.\n",
    "\n",
    "ordinal_features = [\n",
    "    \"Lot Shape\",\n",
    "    \"Land Slope\",\n",
    "    \"Exter Qual\",\n",
    "    \"Exter Cond\",\n",
    "    \"Bsmt Qual\",\n",
    "    \"Bsmt Cond\",\n",
    "    \"Bsmt Exposure\",\n",
    "    \"BsmtFin Type 1\",\n",
    "    \"BsmtFin Type 2\",\n",
    "    \"Heating QC\",\n",
    "    \"Kitchen Qual\",\n",
    "    \"Functional\",\n",
    "    \"Fireplace Qu\",\n",
    "    \"Garage Finish\",\n",
    "    \"Garage Qual\",\n",
    "    \"Garage Cond\",\n",
    "    \"Paved Drive\",\n",
    "    \"Pool QC\",\n",
    "    \"Fence\"\n",
    "]\n",
    "nominal_features = [\n",
    "    \"MS Zoning\",\n",
    "    \"Street\",\n",
    "    \"Alley\",\n",
    "    \"Land Contour\",\n",
    "    \"Utilities\",\n",
    "    \"Lot Config\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition 1\",\n",
    "    \"Condition 2\",\n",
    "    \"Bldg Type\",\n",
    "    \"House Style\",\n",
    "    \"Roof Style\",\n",
    "    \"Roof Matl\",\n",
    "    \"Exterior 1st\",\n",
    "    \"Exterior 2nd\",\n",
    "    \"Mas Vnr Type\",\n",
    "    \"Foundation\",\n",
    "    \"Heating\",\n",
    "    \"Central Air\",\n",
    "    \"Electrical\",\n",
    "    \"Garage Type\",\n",
    "    \"Misc Feature\",\n",
    "    \"Sale Type\",\n",
    "    \"Sale Condition\"\n",
    "]\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "QO-_nNb63o58",
    "outputId": "961f58b9-4360-4d5f-f7c6-7b1fd9f74be1"
   },
   "source": [
    "oe = OrdinalEncoder()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "df_nominal[ordinal_features] = oe.fit_transform( df_nominal[ordinal_features])\n",
    "\n",
    "#example test :\n",
    "df_nominal[\"Lot Shape\"].head()\n",
    "'''\n",
    "\n",
    "# moshkel injast ke bar asase alphabet chide nashode va encoder bar asase tartib encode nemishe pas dasti map mikonim:\n",
    "\n",
    "\n",
    "ordinal_mapping = {\n",
    "    \"Lot Shape\": {'IR3': 0, 'IR2': 1, 'IR1': 2, 'Reg': 3},\n",
    "    \"Land Slope\": {'Sev': 0, 'Mod': 1, 'Gtl': 2},\n",
    "    \"Exter Qual\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Exter Cond\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Bsmt Qual\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Bsmt Cond\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Bsmt Exposure\": {'No': 0, 'Mn': 1, 'Av': 2, 'Gd': 3},\n",
    "    \"BsmtFin Type 1\": {'Unf': 0, 'LwQ': 1, 'BLQ': 2, 'Rec': 3, 'ALQ': 4, 'GLQ': 5},\n",
    "    \"BsmtFin Type 2\": {'Unf': 0, 'LwQ': 1, 'BLQ': 2, 'Rec': 3, 'GLQ': 4, 'ALQ': 5},\n",
    "    \"Heating QC\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Kitchen Qual\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Functional\": {'Sal': 0, 'Sev': 1, 'Maj2': 2, 'Maj1': 3, 'Min2': 4, 'Min1': 5, 'Mod': 6, 'Typ': 7},\n",
    "    \"Fireplace Qu\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Garage Finish\": {'Unf': 0, 'RFn': 1, 'Fin': 2},\n",
    "    \"Garage Qual\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Garage Cond\": {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4},\n",
    "    \"Paved Drive\": {'N': 0, 'P': 1, 'Y': 2},\n",
    "    \"Pool QC\": {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3},\n",
    "    \"Fence\": {'MnWw': 0, 'MnPrv': 1, 'GdWo': 2, 'GdPrv': 3}\n",
    "}\n",
    "\n",
    "\n",
    "# Ø§Ø¹Ù…Ø§Ù„ mapping Ø±ÙˆÛŒ df_nominal\n",
    "for col, mapping in ordinal_mapping.items():\n",
    "    df[col] = df[col].map(mapping)\n",
    "\n",
    "# Ø­Ø§Ù„Ø§ df_nominal Ø®ÙˆØ¯Ø´ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡\n",
    "df[\"Lot Shape\"].head()\n",
    "df.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "DiITxuij9Dbr",
    "outputId": "79ba5148-c6e5-4604-b371-ee2d4d11dcb6"
   },
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "encoded = ohe.fit_transform(df[nominal_features])\n",
    "encoded_df = pd.DataFrame(encoded, columns=ohe.get_feature_names_out(nominal_features),index=df.index ) # bedune index= moshkel NaN dashtim bade .tail\n",
    "df = pd.concat([df.drop(columns=nominal_features), encoded_df], axis=1)\n",
    "\n",
    "df.tail()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CUOmUg62-0X6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "334b865e-183a-4791-d5c8-461afcd1f6b9"
   },
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dV0lFI6t_l9n",
    "outputId": "53003548-9fd4-42b4-a148-9d572f69e7f1"
   },
   "source": [
    "df.shape\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayerWnrFj-OS"
   },
   "source": [
    "## ğŸ”¹ Step 6:  Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cmOzqeCcj9_P"
   },
   "source": [
    "# TODO: Try different scaling techniques:\n",
    "# - StandardScaler\n",
    "# - MinMaxScaler\n",
    "# - RobustScaler\n",
    "# Decide based on the distribution of features.\n",
    "rs = RobustScaler()\n",
    "df[num_cols] = rs.fit_transform(df[num_cols])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8NozkS2kCDE"
   },
   "source": [
    "## ğŸ”¹ Step 7: Feature Selection & Feature Creation ğŸ’¡"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "elKATS4vj82a"
   },
   "source": [
    "# TODO: Select the most useful features.\n",
    "# Try:\n",
    "# - Correlation thresholding and Removing highly collinear features\n",
    "# - decide yourself for dropping useless ones\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtering features (selecting)\n",
    "target = 'SalePrice'\n",
    "\n",
    "# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ numeric\n",
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "numeric_cols = numeric_df.columns.tolist()\n",
    "\n",
    "# correlation Ø¨Ø§ target\n",
    "cor_target = numeric_df.corr()[target].abs()\n",
    "\n",
    "# Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ |corr| < 0.1\n",
    "relevant_features = cor_target[cor_target >= 0.1].index.tolist()\n",
    "df_filtered = df[relevant_features]\n",
    "\n",
    "# multicollinear check\n",
    "corr_matrix = df_filtered.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "df_cleaned = df_filtered.drop(columns=to_drop)\n",
    "\n",
    "# ÙÙ‚Ø· numeric Ù‡Ø§ÛŒÛŒ Ú©Ù‡ Ø­Ø°Ù Ø´Ø¯Ù† Ø¨Ù‡ Ø®Ø§Ø·Ø± low correlation\n",
    "numeric_removed = list(set(numeric_cols) - set(relevant_features))\n",
    "\n",
    "print(\"Numeric columns removed due to low correlation with target:\", numeric_removed)\n",
    "print(\"Columns removed due to multicollinearity:\", to_drop)\n",
    "print(\"Remaining columns:\", df_cleaned.columns.tolist())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8uVNmLLND1P",
    "outputId": "766040e1-e0bf-41cc-aba1-8bab15ead2c6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ÙÙ‚Ø· correlation Ù‡Ø± Ø³ØªÙˆÙ† Ø¨Ø§ target\n",
    "cor_target = df_cleaned.corr(numeric_only=True)['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6, 12))  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø³ØªÙˆÙ†\n",
    "sns.heatmap(cor_target.to_frame(), annot=True, cmap='coolwarm')  # ØªØ¨Ø¯ÛŒÙ„ Series Ø¨Ù‡ DataFrame\n",
    "plt.title(\"Correlation of Features with SalePrice\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NmPEq3pINM5W",
    "outputId": "3a3ff25e-cbb4-4459-9aab-cf042cc35931"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(df.columns.tolist())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rvwzr9JKdj2n",
    "outputId": "dc0657c9-f177-4634-ed45-937f80191205"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "irzYn2YHkFuu",
    "outputId": "31f7a474-c1c7-4e8b-d600-389ddf4a4c3d"
   },
   "source": [
    "# TODO: Create at least 2 NEW features.\n",
    "# Examples:\n",
    "# - Age of house: df[\"HouseAge\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\n",
    "# - Interaction: df[\"Quality_x_Size\"] = df[\"OverallQual\"] * df[\"GrLivArea\"]\n",
    "# - Non-linear: df[\"Log_LotArea\"] = np.log1p(df[\"LotArea\"])\n",
    "import numpy as np\n",
    "\n",
    "# 1. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø§Ø³ØªØ§Ø¯\n",
    "df[\"HouseAge\"] = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "df[\"Quality_x_Size\"] = df[\"Overall Qual\"] * df[\"Gr Liv Area\"]\n",
    "df[\"Log_LotArea\"] = np.where(\n",
    "    ~df[\"Lot Area\"].isna(),\n",
    "    np.log1p(df[\"Lot Area\"]),\n",
    "    0\n",
    ")\n",
    "\n",
    "# 2. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ\n",
    "df[\"TotalSF\"] = df[\"Total Bsmt SF\"] + df[\"1st Flr SF\"] + df[\"2nd Flr SF\"]\n",
    "df[\"TotalPorchSF\"] = (df[\"Open Porch SF\"] + df[\"Enclosed Porch\"] +\n",
    "                      df[\"3Ssn Porch\"] + df[\"Screen Porch\"])\n",
    "df[\"TotalBathrooms\"] = (df[\"Full Bath\"] + 0.5 * df[\"Half Bath\"] +\n",
    "                         df[\"Bsmt Full Bath\"] + 0.5 * df[\"Bsmt Half Bath\"])\n",
    "df[\"TotalRooms\"] = df[\"TotRms AbvGrd\"] + df.get(\"BsmtRooms\", 0)  # Ù…Ù…Ú©Ù†Ù‡ Ø³ØªÙˆÙ† BsmtRooms Ù†Ø¨Ø§Ø´Ù‡\n",
    "df[\"TotalOutdoorSF\"] = df.get(\"Wood Deck SF\", 0) + df[\"TotalPorchSF\"] + df.get(\"Pool Area\", 0)\n",
    "\n",
    "# 3. Ù†Ø³Ø¨Øªâ€ŒÙ‡Ø§ (Ratios)\n",
    "df[\"GrLivArea_per_Room\"] = np.where(\n",
    "    (df[\"TotRms AbvGrd\"] > 0) & (~df[\"TotRms AbvGrd\"].isna()),\n",
    "    df[\"Gr Liv Area\"] / df[\"TotRms AbvGrd\"],\n",
    "    0\n",
    ")\n",
    "\n",
    "df[\"GarageArea_per_Car\"] = np.where(\n",
    "    (df[\"Garage Cars\"] > 0) & (~df[\"Garage Cars\"].isna()),\n",
    "    df[\"Garage Area\"] / df[\"Garage Cars\"],\n",
    "    0\n",
    ")\n",
    "\n",
    "df[\"Bath_per_Bedroom\"] = np.where(\n",
    "    (df[\"Bedroom AbvGr\"] > 0) & (~df[\"Bedroom AbvGr\"].isna()),\n",
    "    df[\"TotalBathrooms\"] / df[\"Bedroom AbvGr\"],\n",
    "    0\n",
    ")\n",
    "\n",
    "df[\"LotArea_per_GrLivArea\"] = df[\"Lot Area\"] / df[\"Gr Liv Area\"]\n",
    "df[\"Year_since_remod\"] = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "\n",
    "# 4. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ (Interactions)\n",
    "df[\"OverallQual_x_TotalSF\"] = df[\"Overall Qual\"] * df[\"TotalSF\"]\n",
    "df[\"OverallQual_x_GrLivArea\"] = df[\"Overall Qual\"] * df[\"Gr Liv Area\"]\n",
    "\n",
    "# 5. ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ / Ø¨ÙˆÙ„ÛŒÙ†\n",
    "df[\"Since_Remodel\"] = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "df[\"Is_Remodeled\"] = (df[\"Year Built\"] != df[\"Year Remod/Add\"]).astype(int)\n",
    "df[\"Has_Pool\"] = (df.get(\"Pool Area\", 0) > 0).astype(int)\n",
    "df[\"Has_Garage\"] = ((df.get(\"Garage Area\", 0) > 0) | (df.get(\"Garage Cars\", 0) > 0)).astype(int)\n",
    "df[\"Has_Basement\"] = (df.get(\"Total Bsmt SF\", 0) > 0).astype(int)\n",
    "df[\"Has_Fireplace\"] = (df.get(\"Fireplaces\", 0) > 0).astype(int)\n",
    "\n",
    "# 6. Ú©ÛŒÙÛŒØª ØªØ±Ú©ÛŒØ¨ÛŒ Ø¢Ø´Ù¾Ø²Ø®Ø§Ù†Ù‡\n",
    "if {\"Kitchen Qual\", \"Kitchen Cond\"}.issubset(df.columns):\n",
    "    df[\"Kitchen_Score\"] = (df[\"Kitchen Qual\"] + df[\"Kitchen Cond\"]) / 2\n",
    "\n",
    "# 7. ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¨ÛŒâ€ŒÙ†Ù‡Ø§ÛŒØª\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df.isna().sum()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    " ğŸ«• to the creation.. we have Nan .. now imputing"
   ],
   "metadata": {
    "id": "YvFKH6aNfdt2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#nan :\n",
    "# Log_LotArea\t341\n",
    "#LotArea_per_GrLivArea\t3\n",
    "# Imputation Ø¨Ø§ Median\n",
    "df[\"Log_LotArea\"].fillna(df[\"Log_LotArea\"].median(), inplace=True)\n",
    "df[\"LotArea_per_GrLivArea\"].fillna(df[\"LotArea_per_GrLivArea\"].median(), inplace=True)\n",
    "\n",
    "df.isna().sum().sum()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwgQczi8fdQu",
    "outputId": "66c4f397-974a-4eb6-9d85-401a89c2351c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohlGPfhykRMs"
   },
   "source": [
    "## ğŸ”¹ Step 8: Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l0Yx7uH5kP_H"
   },
   "source": [
    "# TODO: Detect and handle outliers.\n",
    "# Methods:\n",
    "# - IQR rule\n",
    "# - Z-score\n",
    "# - Visualization (boxplots, scatterplots)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# IQR\n",
    "\n",
    "# Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "Q1 = df[num_cols].quantile(0.25)\n",
    "Q3 = df[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((df[num_cols] < (Q1 - 1.5 * IQR)) | (df[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "# 1.5 standarde ama baraye taghire sensivity mishe avaz kard\n",
    "\n",
    "print(f'Number of outliers detected by boxplot method: {outliers.sum()}')\n",
    "print(f'Percentage of outliers: {outliers.sum()/len(df)*100:.2f}%')\n",
    "\n",
    "df[outliers].shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm_m1p1fhvPw",
    "outputId": "1bba6e47-5c97-407a-ee17-56cdcda4beb6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "z_score = np.abs((df[num_cols] - df[num_cols].mean())/ df[num_cols].std())\n",
    "outliers = (z_score > 1.5).any(axis=1) #inja all hame feature haro barresi mikone va agar hame out budan True (100% )\n",
    "df[outliers].shape\n",
    "#df[~outliers].shape #unai ke outlier nistan\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ne_JTSxJh6vO",
    "outputId": "b9be4399-9c47-4233-c645-45cd7c43616d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#boxplot;\n",
    "# Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(numeric_cols), batch_size):\n",
    "    cols_batch = numeric_cols[i:i+batch_size]\n",
    "    df_batch = df[cols_batch]\n",
    "\n",
    "    plt.figure(figsize=(12, len(cols_batch) * 1.5))\n",
    "    for j, col in enumerate(cols_batch, 1):\n",
    "        plt.subplot(len(cols_batch), 1, j)\n",
    "        sns.boxplot(x=df[col], color=\"skyblue\")\n",
    "        plt.title(f\"Boxplot - {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "id": "w7sX3cubiUBv",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "4b8d82c8-5d2d-42a9-8fbb-ce67d45acbd7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#scatterplot\n",
    "\n",
    "# -- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ --\n",
    "target_col = 'SalePrice'   # Ø§Ø³Ù… Ø³ØªÙˆÙ† ØªØ§Ø±Ú¯Øª\n",
    "batch_size = 5             # ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¯Ø± Ù‡Ø± Ø³Ø±ÛŒ\n",
    "\n",
    "# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ ØºÛŒØ± ØªØ§Ø±Ú¯Øª\n",
    "numeric_cols = [col for col in df.select_dtypes(include=np.number).columns if col != target_col]\n",
    "\n",
    "# Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ: Ø§ÙˆÙ„ Ø­Ø±ÙˆÙØŒ Ø¨Ø¹Ø¯ Ø§Ø¹Ø¯Ø§Ø¯\n",
    "numeric_cols = sorted(numeric_cols, key=lambda x: (str(x)[0].isdigit(), str(x).lower()))\n",
    "\n",
    "# Ø±Ø³Ù… Scatterplot Ø¨Ù‡ ØµÙˆØ±Øª Batch\n",
    "for i in range(0, len(numeric_cols), batch_size):\n",
    "    cols_batch = numeric_cols[i:i+batch_size]\n",
    "\n",
    "    plt.figure(figsize=(12, len(cols_batch) * 3))\n",
    "    for j, col in enumerate(cols_batch, 1):\n",
    "        plt.subplot(len(cols_batch), 1, j)\n",
    "        sns.scatterplot(x=df[col], y=df[target_col], alpha=0.6, color='teal', edgecolor=None)\n",
    "        plt.title(f\"Scatterplot: {col} vs {target_col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(target_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "9-HJ6S25kcFz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "6500f9fd-57a1-40bf-d3da-eedd55631595"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDirz02_kU1e"
   },
   "source": [
    "## ğŸ”¹ Step 9: Skewness Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bz0Kke71kTxQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76c5cd7d-587f-490d-a939-28dcdac296f7"
   },
   "source": [
    "# TODO: Check skewness of numerical features.\n",
    "# Apply log, sqrt, Box-Cox, or Yeo-Johnson depending on distribution.\n",
    "\n",
    "from scipy.stats import boxcox, yeojohnson\n",
    "\n",
    "# 1ï¸âƒ£ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ numeric ÙˆØ§Ù‚Ø¹ÛŒ\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# 2ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ skewness Ù‚Ø¨Ù„ Ø§Ø² transformation\n",
    "skew_values = df[numeric_cols].skew()\n",
    "print(\"Skewness before transformation:\\n\", skew_values)\n",
    "\n",
    "# 3ï¸âƒ£ Threshold Ø¨Ø±Ø§ÛŒ skewed Ø¨ÙˆØ¯Ù†\n",
    "skew_threshold = 0.75\n",
    "\n",
    "# 4ï¸âƒ£ Ú©Ù¾ÛŒ dataframe Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ transformation\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# 5ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ transformation Ø¨Ø± Ø§Ø³Ø§Ø³ ØªÙˆØ²ÛŒØ¹\n",
    "for col in numeric_cols:\n",
    "    skew_val = skew_values[col]\n",
    "\n",
    "    if abs(skew_val) > skew_threshold:\n",
    "        # Positive and > 0 -> Box-Cox\n",
    "        if (df_transformed[col] > 0).all():\n",
    "            df_transformed[col], _ = boxcox(df_transformed[col])\n",
    "            print(f\"Applied Box-Cox on {col}\")\n",
    "        # Ø§Ú¯Ø± ØµÙØ± ÛŒØ§ Ù…Ù†ÙÛŒ Ø¯Ø§Ø±Ù‡ -> Yeo-Johnson\n",
    "        elif (df_transformed[col] <= 0).any():\n",
    "            df_transformed[col], _ = yeojohnson(df_transformed[col])\n",
    "            print(f\"Applied Yeo-Johnson on {col}\")\n",
    "          #Optional: log/sqrt Ø¨Ø±Ø§ÛŒ skew Ø®ÛŒÙ„ÛŒ Ø´Ø¯ÛŒØ¯ (Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒ)\n",
    "        elif skew_val > 2:\n",
    "           df_transformed[col] = np.log1p(df_transformed[col])\n",
    "        elif skew_val < -2:\n",
    "            df_transformed[col] = np.sqrt(df_transformed[col].max() - df_transformed[col])\n",
    "\n",
    "# 6ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ skewness Ø¨Ø¹Ø¯ Ø§Ø² transformation\n",
    "new_skew = df_transformed[numeric_cols].skew()\n",
    "print(\"Skewness after transformation:\\n\", new_skew)\n",
    "\n",
    "# 7ï¸âƒ£ df_transformed Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ scaling Ùˆ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Ù„ÛŒØ³Øª featureÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒØ®ÙˆØ§ÛŒ drop Ú©Ù†ÛŒ\n",
    "drop_cols = [\n",
    "    'Has_Pool', 'Has_Shed', 'Garage_Carport',\n",
    "    'OverallQual_x_GrLivArea', 'TotalBsmtSF_per_Room', 'Age_House',\n",
    "    'TotRmsAbvGrd', 'GarageCars', 'LotFrontage'\n",
    "]\n",
    "\n",
    "# Ú†Ú© Ú©Ù† Ú©Ù‡ ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ drop Ø¨Ø´Ù†\n",
    "drop_cols_existing = [col for col in drop_cols if col in df_transformed.columns]\n",
    "\n",
    "# drop Ú©Ø±Ø¯Ù† Ø§Ø² df\n",
    "df_transformed = df_transformed.drop(columns=drop_cols_existing)\n",
    "\n",
    "# ØªØ§ÛŒÛŒØ¯ ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ø¹Ø¯ Ø§Ø² drop\n",
    "print(f\"New shape of df: {df_transformed.shape}\")"
   ],
   "metadata": {
    "id": "jUpdtyf55r-Z",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4bc22766-ff3e-45d1-df56-48b4882bf0b4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------- Step 1: Calculate skewness ----------\n",
    "skewness = df_transformed.skew()\n",
    "\n",
    "# ---------- Step 2: Calculate outlier percentage ----------\n",
    "Q1 = df_transformed.quantile(0.25)\n",
    "Q3 = df_transformed.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outlier_mask = ((df_transformed < (Q1 - 1.5 * IQR)) | (df_transformed > (Q3 + 1.5 * IQR)))\n",
    "outlier_percent = outlier_mask.sum() / len(df) * 100\n",
    "\n",
    "# ---------- Step 3: Classify features ----------\n",
    "drop_features = []\n",
    "clip_features = []\n",
    "\n",
    "for col in df_transformed.columns:\n",
    "    if col in skewness.index:  # ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒâ€ŒÙ‡Ø§\n",
    "        if abs(skewness[col]) > 1 and outlier_percent[col] > 20:\n",
    "            drop_features.append(col)\n",
    "        elif outlier_percent[col] > 10:\n",
    "            clip_features.append(col)\n",
    "\n",
    "print(\"Features to DROP (too skewed + high outliers):\", drop_features)\n",
    "print(\"Features to CLIP (moderate skew, outlier handling):\", clip_features)\n",
    "\n",
    "# ---------- Step 4: Apply clipping ----------\n",
    "df_clean = df_transformed.copy()\n",
    "for col in clip_features:\n",
    "    lower = Q1[col] - 1.5 * IQR[col]\n",
    "    upper = Q3[col] + 1.5 * IQR[col]\n",
    "    df_clean[col] = df_clean[col].clip(lower=lower, upper=upper)"
   ],
   "metadata": {
    "id": "ldnaK53l6Y2S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "742dab03-b0a4-41d1-cbbc-ab73e12f936a"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Ø­Ø°Ù ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ ØºÛŒØ± Ù…ÙÛŒØ¯\n",
    "df_clean = df_transformed.drop(columns=['MS Zoning_RL', 'Roof Style_Gable'])\n",
    "\n",
    "# Ú©Ù„Ù€ÛŒÙ¾ Ø¨Ø±Ø§ÛŒ ÙÛŒÚ†Ø±Ù‡Ø§ÛŒ Ø¯ÛŒÚ¯Ù‡\n",
    "clip_features = [\n",
    "    'Exter Cond', 'BsmtFin Type 2', 'BsmtFin SF 2', 'Fireplace Qu',\n",
    "    'Enclosed Porch', 'MS Zoning_RM', 'Land Contour_Lvl', 'Lot Config_Corner',\n",
    "    'Neighborhood_NAmes', 'Condition 1_Norm', 'Bldg Type_1Fam',\n",
    "    'House Style_1.5Fin', 'Roof Style_Hip', 'Exterior 1st_HdBoard',\n",
    "    'Exterior 1st_MetalSd', 'Exterior 1st_Wd Sdng', 'Exterior 2nd_HdBoard',\n",
    "    'Exterior 2nd_MetalSd', 'Exterior 2nd_Wd Sdng', 'Foundation_BrkTil',\n",
    "    'Sale Type_WD ', 'Sale Condition_Normal', 'GarageArea_per_Car',\n",
    "    'Bath_per_Bedroom', 'LotArea_per_GrLivArea', 'OverallQual_x_TotalSF'\n",
    "]\n",
    "\n",
    "Q1 = df_clean[clip_features].quantile(0.25)\n",
    "Q3 = df_clean[clip_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "for col in clip_features:\n",
    "    lower = Q1[col] - 1.5 * IQR[col]\n",
    "    upper = Q3[col] + 1.5 * IQR[col]\n",
    "    df_clean[col] = df_clean[col].clip(lower=lower, upper=upper)\n",
    "\n",
    "# Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ\n",
    "print(\"Final shape:\", df_clean.shape)"
   ],
   "metadata": {
    "id": "NwusMRYH8K78",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9f1c8564-ed24-4b26-bef6-878d19333a48"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# IQR\n",
    "\n",
    "# Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "Q1 = df_clean[num_cols].quantile(0.25)\n",
    "Q3 = df_clean[num_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((df_clean[num_cols] < (Q1 - 1.5 * IQR)) | (df_clean[num_cols] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "# 1.5 standarde ama baraye taghire sensivity mishe avaz kard\n",
    "\n",
    "print(f'Number of outliers detected by boxplot method: {outliers.sum()}')\n",
    "print(f'Percentage of outliers: {outliers.sum()/len(df)*100:.2f}%')\n",
    "\n",
    "df_clean[outliers].shape"
   ],
   "metadata": {
    "id": "LzEVxxL88TIG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fdeec579-0cce-4e1a-f18e-8a516a3d9f13"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import yeojohnson, boxcox\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Ø¨Ø±Ø±Ø³ÛŒ skewness Ø¯ÙˆØ¨Ø§Ø±Ù‡\n",
    "skewness = df_clean.skew().sort_values(ascending=False)\n",
    "\n",
    "# Ø§Ù†ØªØ®Ø§Ø¨ ÙÙ‚Ø· ÙÛŒÚ†Ø±Ù‡Ø§ÛŒÛŒ Ú©Ù‡ skew Ø¨Ø§Ù„Ø§ Ø¯Ø§Ø±Ù†\n",
    "skewed_features = skewness[abs(skewness) > 0.75].index\n",
    "\n",
    "print(\"Number of skewed features before re-transform:\", len(skewed_features))\n",
    "\n",
    "# Ø§Ø¹Ù…Ø§Ù„ ØªØ±Ù†Ø³ÙÙˆØ±Ù… Ù…Ù†Ø§Ø³Ø¨\n",
    "for col in skewed_features:\n",
    "    if (df_clean[col] <= 0).any():\n",
    "        # Ø§Ú¯Ø± ØµÙØ± ÛŒØ§ Ù…Ù†ÙÛŒ Ø¯Ø§Ø±Ù‡ â†’ Yeo-Johnson\n",
    "        df_clean[col], _ = yeojohnson(df_clean[col])\n",
    "    else:\n",
    "        # ÙÙ‚Ø· Ù…Ø«Ø¨Øª â†’ Box-Cox\n",
    "        df_clean[col] = boxcox1p(df_clean[col], 0.15)\n",
    "\n",
    "# Ú†Ú© Ù…Ø¬Ø¯Ø¯ skewness\n",
    "print(\"Skewness after re-transform:\")\n",
    "print(df_clean[skewed_features].skew().sort_values(ascending=False))"
   ],
   "metadata": {
    "id": "0KqLkbzD9zeA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e54cc001-7257-4934-e441-47235b272c34"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Ù„ÛŒØ³Øª ÙÛŒÚ†Ø±Ù‡Ø§ ---\n",
    "features_to_drop = ['MS Zoning_RL', 'Roof Style_Gable']  # Ø®ÛŒÙ„ÛŒ skewed + high outliers\n",
    "features_to_clip = [\n",
    "    'Exter Cond', 'BsmtFin Type 2', 'BsmtFin SF 2', 'Fireplace Qu', 'Enclosed Porch',\n",
    "    'MS Zoning_RM', 'Land Contour_Lvl', 'Lot Config_Corner', 'Neighborhood_NAmes',\n",
    "    'Condition 1_Norm', 'Bldg Type_1Fam', 'House Style_1.5Fin', 'Roof Style_Hip',\n",
    "    'Exterior 1st_HdBoard', 'Exterior 1st_MetalSd', 'Exterior 1st_Wd Sdng',\n",
    "    'Exterior 2nd_HdBoard', 'Exterior 2nd_MetalSd', 'Exterior 2nd_Wd Sdng',\n",
    "    'Foundation_BrkTil', 'Sale Type_WD ', 'Sale Condition_Normal', 'GarageArea_per_Car',\n",
    "    'Bath_per_Bedroom', 'LotArea_per_GrLivArea', 'OverallQual_x_TotalSF'\n",
    "]\n",
    "\n",
    "# --- Ø§Ø¹Ù…Ø§Ù„ drop ---\n",
    "df_clean_dropped = df_clean.drop(columns=features_to_drop, errors='ignore')\n",
    "\n",
    "# --- Ø§Ø¹Ù…Ø§Ù„ clip ---\n",
    "for col in features_to_clip:\n",
    "    if col in df_clean_dropped.columns:\n",
    "        lower = df_clean_dropped[col].quantile(0.01)\n",
    "        upper = df_clean_dropped[col].quantile(0.99)\n",
    "        df_clean_dropped[col] = df_clean_dropped[col].clip(lower, upper)\n",
    "\n",
    "# --- Ø¨Ø±Ø±Ø³ÛŒ outlierÙ‡Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ---\n",
    "def outlier_stats(df):\n",
    "    outlier_counts = []\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5*iqr\n",
    "        upper = q3 + 1.5*iqr\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "        outlier_counts.append(len(outliers))\n",
    "    total_outliers = sum(outlier_counts)\n",
    "    perc_outliers = total_outliers / (df.shape[0] * df.select_dtypes(include=np.number).shape[1]) * 100\n",
    "    print(f\"Number of outliers detected by boxplot method: {total_outliers}\")\n",
    "    print(f\"Percentage of outliers: {perc_outliers:.2f}%\")\n",
    "    print(df.shape)\n",
    "\n",
    "outlier_stats(df_clean_dropped)"
   ],
   "metadata": {
    "id": "Z1_SNXYX-fY-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2ede4653-69da-4436-c0e3-7da6a4ea4a9b"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "z_score = np.abs((df_clean_dropped[num_cols] - df_clean_dropped[num_cols].mean())/ df_clean_dropped[num_cols].std())\n",
    "outliers = (z_score > 3).any(axis=1) #inja all hame feature haro barresi mikone va agar hame out budan True (100% )\n",
    "df_clean_dropped[outliers].shape\n",
    "#df[~outliers].shape #unai ke outlier nistan"
   ],
   "metadata": {
    "id": "xq_9wiuGC5sB"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for col in df_clean_dropped.select_dtypes(include=[\"float64\", \"int64\"]).columns:   #for numerics fill with median\n",
    "    df_clean_dropped[col].fillna(df_clean_dropped[col].median(), inplace=True)"
   ],
   "metadata": {
    "id": "NSLpNaL__Elw"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_clean_dropped.isna().sum().sum()"
   ],
   "metadata": {
    "id": "ZpEh-I5U_erh"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ğŸ”¹ Step 10: remove duplicates"
   ],
   "metadata": {
    "id": "o2J0iiYoWANg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ duplicate\n",
    "num_duplicates = df_clean.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "# Ø­Ø°Ù duplicates Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± df_clean_dropped\n",
    "df_clean_dropped = df_clean.drop_duplicates()\n",
    "print(f\"Shape after dropping duplicates: {df_clean_dropped.shape}\")"
   ],
   "metadata": {
    "id": "vWUpaXGJWC-k"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ\n",
    "numeric_cols = df_clean_dropped.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "batch_size = 5\n",
    "for i in range(0, len(numeric_cols), batch_size):\n",
    "    cols_batch = numeric_cols[i:i+batch_size]\n",
    "    df_batch = df_clean_dropped[cols_batch]\n",
    "\n",
    "    plt.figure(figsize=(12, len(cols_batch) * 1.5))\n",
    "    for j, col in enumerate(cols_batch, 1):\n",
    "        plt.subplot(len(cols_batch), 1, j)\n",
    "        sns.boxplot(x=df_clean_dropped[col], color=\"skyblue\")\n",
    "        plt.title(f\"Boxplot - {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "DYa0F9PhAM2P"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ\n",
    "target_col = 'SalePrice'   # Ø§Ø³Ù… Ø³ØªÙˆÙ† ØªØ§Ø±Ú¯Øª\n",
    "batch_size = 5             # ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ Ø¯Ø± Ù‡Ø± Ø³Ø±ÛŒ\n",
    "\n",
    "# ÙÙ‚Ø· Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ ØºÛŒØ± ØªØ§Ø±Ú¯Øª\n",
    "numeric_cols = [col for col in df_clean_dropped.select_dtypes(include=np.number).columns if col != target_col]\n",
    "\n",
    "# Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ: Ø§ÙˆÙ„ Ø­Ø±ÙˆÙØŒ Ø¨Ø¹Ø¯ Ø§Ø¹Ø¯Ø§Ø¯\n",
    "numeric_cols = sorted(numeric_cols, key=lambda x: (str(x)[0].isdigit(), str(x).lower()))\n",
    "\n",
    "# Ø±Ø³Ù… Scatterplot Ø¨Ù‡ ØµÙˆØ±Øª Batch\n",
    "for i in range(0, len(numeric_cols), batch_size):\n",
    "    cols_batch = numeric_cols[i:i+batch_size]\n",
    "\n",
    "    plt.figure(figsize=(12, len(cols_batch) * 3))\n",
    "    for j, col in enumerate(cols_batch, 1):\n",
    "        plt.subplot(len(cols_batch), 1, j)\n",
    "        sns.scatterplot(x=df_clean_dropped[col], y=df_clean_dropped[target_col], alpha=0.6, color='teal', edgecolor=None)\n",
    "        plt.title(f\"Scatterplot: {col} vs {target_col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(target_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "sTQmUrEmAXk8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import metrics_helper\n",
    "metrics_plot(df_clean_dropped)"
   ],
   "metadata": {
    "id": "PH1oNOkXAh6d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlW4RbaTkeSu"
   },
   "source": [
    "## ğŸ’¾ Step 11: Save Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "naZHc5dnkamR"
   },
   "source": [
    "# Save your final cleaned and engineered dataset to CSV.\n",
    "df_clean_dropped.to_csv(\"AmesHousing_clean_by_Arianshs.csv\", index=False)\n",
    "print(\"âœ… Cleaned dataset saved successfully!\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a80f4e76"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "nDirz02_kU1e"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
